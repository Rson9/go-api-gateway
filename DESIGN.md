# 架构设计文档

## 1. 目标 (Goals)

本项目旨在创建一个轻量级但功能强大的 API 网关，具备以下特点：
- **高性能**: 利用 Go 的并发特性处理大量请求。
- **可扩展**: 易于添加新的中间件和功能。
- **易配置**: 通过简单的配置文件进行路由管理。

## 2. 高层架构

+----------------+      +-------------------+      +--------------------+
|      Client    |----->|   Go API Gateway  |----->|   Backend Service  |
| (e.g., curl)   |      |   (Port :8080)    |      |    (Port :9090)    |
+----------------+      +-------------------+      +--------------------+


## 3. 核心模块设计 (V1)

- **配置模块 (`Viper`)**: 负责从 `configs/config.yaml` 加载服务端口和后端目标 URL。
- **代理模块 (`internal/proxy`)**: 使用 Go 标准库 `net/http/httputil.NewSingleHostReverseProxy` 创建一个核心的反向代理处理器。它接收所有进入的 HTTP 请求，并将其转发到配置中指定的单一后端服务。
- **服务模块 (`internal/server`)**: 负责启动一个标准的 `http.Server`，并使用代理模块创建的处理器来处理所有请求。

### 路由模块 (`internal/router`)
路由模块是 V2 版本的核心。它取代了原有的单一代理逻辑。

**数据结构**:
- `config.Route`: 定义了路由的 `name`, `path` 和 `target`。
- `router`: 作为主 `http.Handler`，持有一个排序后的路由列表 `[]*config.Route` 和一个预先构建的代理映射 `map[string]*httputil.ReverseProxy`。

**路由匹配逻辑**:
1.  **初始化**: 在启动时，从配置加载所有路由规则。
2.  **排序**: 为了确保最具体的路径（更长的路径）优先匹配，所有路由规则会**按路径长度降序排序**。例如，`/service/a/users` 会排在 `/service/a` 之前。这是一个关键的细节，可以防止宽泛的规则意外地“劫持”了更具体的请求。
3.  **代理预构建**: 为每个路由的目标地址（target）预先创建一个 `httputil.ReverseProxy` 实例并缓存起来。这避免了在每次请求时都创建新代理的开销，显著提高了性能。
4.  **请求处理**: 当一个请求到达时，`router` 的 `ServeHTTP` 方法会遍历排序后的路由列表。它使用 `strings.HasPrefix` 来检查请求的 URL 路径是否与路由的 `path` 匹配。一旦找到第一个匹配项，请求就会被分发给对应的预构建代理，并且匹配过程立即停止。
5.  **未匹配**: 如果遍历完所有路由都没有找到匹配项，服务器会返回一个标准的 `HTTP 404 Not Found` 响应。

**待讨论与未来改进**:
- **性能**: 对于大规模路由（数千条），线性扫描的性能可能会下降。未来可以考虑使用更高效的路由匹配数据结构，如**基数树 (Radix Tree/Trie)**，它可以将匹配时间复杂度从 O(N) 降低到 O(k)，其中 k 是 URL 路径的长度。

## 4. 中间件架构 (Middleware Architecture)

为了在不侵入核心路由逻辑的情况下添加日志、认证、限流等横切功能，我们引入了标准的 Go HTTP 中间件模式。中间件是一个函数，它接收一个 `http.Handler` 并返回一个新的 `http.Handler`，形成一个处理链。

`type Middleware func(http.Handler) http.Handler`

### 4.1 请求限流中间件

**目标**: 防止后端服务被过多请求压垮。

**算法选择**:
我们选择了**令牌桶 (Token Bucket)** 算法。相比于漏桶算法，令牌桶能够更好地应对突发流量（bursts），因为它允许在桶容量内的请求立即通过，这更符合 API 调用的常见模式。

**实现细节**:
- **`internal/limiter/TokenBucket`**: 这是限流算法的核心实现。
    - 它包含 `rate` (每秒令牌生成速率) 和 `burst` (桶容量) 两个核心参数。
    - **并发安全**: `TokenBucket` 结构体使用 `sync.Mutex` 来保护对内部 `tokens` 计数器和 `lastTokenAt` 时间戳的访问。这对于保证在 Go 的并发请求模型中数据一致性至关重要，能有效防止竞态条件。
- **`internal/middleware/RateLimit`**: 这是一个中间件工厂函数。
    - 它接收一个 `TokenBucket` 实例，并返回一个标准的 `http.Handler` 包装器。
    - 在处理每个请求前，它首先调用 `limiter.Allow()`。
    - 如果允许通行，则调用链中的下一个 `handler.ServeHTTP()`。
    - 如果被拒绝，则立即中止请求链，并向客户端返回 `HTTP 429 Too Many Requests` 状态码。

**未来改进**:
- **分布式限流**: 当前的限流器是基于内存的，其状态在单个网关实例中。如果网关进行水平扩展（部署多个实例），每个实例都会有自己的令牌桶，无法实现全局限流。下一步可以引入 **Redis** 来存储令牌桶的状态，实现所有网关实例共享的分布式限流。
- **按路由限流**: 当前是全局限流。未来可以扩展配置，允许为每个路由规则定义自己独立的限流策略。